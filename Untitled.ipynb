{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5344d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Booking ID  User Age Preferred Age Group  Seat Number  Row  Column  \\\n",
      "0           1        23               18-25           12    2       6   \n",
      "1           2        34               25-40           15    3       3   \n",
      "2           3        45               40-60           20    4       2   \n",
      "3           4        62                 60+            9    2       3   \n",
      "4           5        29               25-40           18    3       6   \n",
      "\n",
      "  Seat Type  Seat Booked  \n",
      "0    Window         True  \n",
      "1     Aisle         True  \n",
      "2    Middle         True  \n",
      "3     Aisle         True  \n",
      "4    Window         True  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data from Excel\n",
    "df = pd.read_csv('train_booking_data.csv')\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa3da9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Booking ID             0\n",
      "User Age               0\n",
      "Preferred Age Group    0\n",
      "Seat Number            0\n",
      "Row                    0\n",
      "Column                 0\n",
      "Seat Type              0\n",
      "Seat Booked            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Fill missing values or drop rows/columns\n",
    "df.fillna({'User Age': df['User Age'].mean(), 'Seat Type': 'Unknown'}, inplace=True)\n",
    "# or\n",
    "df.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e84e0998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding for categorical variables\n",
    "df_encoded = pd.get_dummies(df[['User Age', 'Preferred Age Group', 'Seat Type']], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "838792a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Convert 'Age Group' to numerical ranges\n",
    "age_group_mapping = {'18-25': 1, '25-40': 2, '40-60': 3, '60+': 4}\n",
    "df['Age Group Numeric'] = df['Preferred Age Group'].map(age_group_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d10d705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Booking ID  User Age Preferred Age Group  Seat Number  Row  Column  \\\n",
      "0           1        23               18-25           12    2       6   \n",
      "1           2        34               25-40           15    3       3   \n",
      "2           3        45               40-60           20    4       2   \n",
      "3           4        62                 60+            9    2       3   \n",
      "4           5        29               25-40           18    3       6   \n",
      "\n",
      "  Seat Type  Seat Booked  Age Group Numeric  Age Scaled  \n",
      "0    Window         True                  1   -1.291475  \n",
      "1     Aisle         True                  2   -0.451698  \n",
      "2    Middle         True                  3    0.388079  \n",
      "3     Aisle         True                  4    1.685916  \n",
      "4    Window         True                  2   -0.833415  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fd63cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Example: Scaling 'Age'\n",
    "scaler = StandardScaler()\n",
    "df['Age Scaled'] = scaler.fit_transform(df[['User Age']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac476756",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_MissingValues' from 'sklearn.utils._param_validation' (C:\\Users\\Diya\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[0;32m      3\u001b[0m X \u001b[38;5;241m=\u001b[39m df_encoded\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSeat Booked\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m y \u001b[38;5;241m=\u001b[39m df_encoded[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSeat Booked\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\imblearn\\__init__.py:52\u001b[0m\n\u001b[0;32m     48\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPartial import of imblearn during the build process.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     53\u001b[0m         combine,\n\u001b[0;32m     54\u001b[0m         ensemble,\n\u001b[0;32m     55\u001b[0m         exceptions,\n\u001b[0;32m     56\u001b[0m         metrics,\n\u001b[0;32m     57\u001b[0m         over_sampling,\n\u001b[0;32m     58\u001b[0m         pipeline,\n\u001b[0;32m     59\u001b[0m         tensorflow,\n\u001b[0;32m     60\u001b[0m         under_sampling,\n\u001b[0;32m     61\u001b[0m         utils,\n\u001b[0;32m     62\u001b[0m     )\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FunctionSampler\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\imblearn\\combine\\__init__.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"The :mod:`imblearn.combine` provides methods which combine\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mover-sampling and under-sampling.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_enn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTEENN\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_tomek\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTETomek\n\u001b[0;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTEENN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTETomek\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\imblearn\\combine\\_smote_enn.py:12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_X_y\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseSampler\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseOverSampler\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\imblearn\\base.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulticlass\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_classification_targets\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_sampling_strategy, check_target_type\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArraysTransformer\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSamplerMixin\u001b[39;00m(BaseEstimator, metaclass\u001b[38;5;241m=\u001b[39mABCMeta):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\imblearn\\utils\\_param_validation.py:908\u001b[0m\n\u001b[0;32m    906\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate_valid_param  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m    907\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m--> 908\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    909\u001b[0m     HasMethods,\n\u001b[0;32m    910\u001b[0m     Hidden,\n\u001b[0;32m    911\u001b[0m     Interval,\n\u001b[0;32m    912\u001b[0m     Options,\n\u001b[0;32m    913\u001b[0m     StrOptions,\n\u001b[0;32m    914\u001b[0m     _ArrayLikes,\n\u001b[0;32m    915\u001b[0m     _Booleans,\n\u001b[0;32m    916\u001b[0m     _Callables,\n\u001b[0;32m    917\u001b[0m     _CVObjects,\n\u001b[0;32m    918\u001b[0m     _InstancesOf,\n\u001b[0;32m    919\u001b[0m     _IterablesNotString,\n\u001b[0;32m    920\u001b[0m     _MissingValues,\n\u001b[0;32m    921\u001b[0m     _NoneConstraint,\n\u001b[0;32m    922\u001b[0m     _PandasNAConstraint,\n\u001b[0;32m    923\u001b[0m     _RandomStates,\n\u001b[0;32m    924\u001b[0m     _SparseMatrices,\n\u001b[0;32m    925\u001b[0m     _VerboseHelper,\n\u001b[0;32m    926\u001b[0m     make_constraint,\n\u001b[0;32m    927\u001b[0m     validate_params,\n\u001b[0;32m    928\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_MissingValues' from 'sklearn.utils._param_validation' (C:\\Users\\Diya\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py)"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X = df_encoded.drop('Seat Booked', axis=1)\n",
    "y = df_encoded['Seat Booked']\n",
    "\n",
    "# Apply SMOTE to balance the dataset\n",
    "smote = SMOTE()\n",
    "X_res, y_res = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00981cd3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m----> 3\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X_res, y_res, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_res' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50da13ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define parameters for synthetic data\n",
    "n_synthetic = 100  # Number of synthetic records\n",
    "age_groups = ['18-25', '25-40', '40-60', '60+']\n",
    "seat_types = ['Window', 'Aisle', 'Middle']\n",
    "\n",
    "# Create synthetic records\n",
    "synthetic_data = {\n",
    "    'Age': np.random.randint(18, 70, size=n_synthetic),\n",
    "    'Age Group': np.random.choice(age_groups, size=n_synthetic),\n",
    "    'Seat Number': np.random.randint(1, 100, size=n_synthetic),\n",
    "    'Row': np.random.randint(1, 20, size=n_synthetic),\n",
    "    'Column': np.random.randint(1, 6, size=n_synthetic),\n",
    "    'Seat Type': np.random.choice(seat_types, size=n_synthetic),\n",
    "    'Seat Booked': [False] * n_synthetic\n",
    "}\n",
    "\n",
    "synthetic_df = pd.DataFrame(synthetic_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d016e81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original data\n",
    "df_booked = pd.read_csv('train_booking_data.csv')\n",
    "\n",
    "# Append synthetic data\n",
    "df_combined = pd.concat([df_booked, synthetic_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5093c54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values if any\n",
    "df_combined.fillna({'User Age': df_combined['User Age'].mean(), 'Seat Type': 'Unknown'}, inplace=True)\n",
    "\n",
    "# Convert categorical variables\n",
    "df_encoded = pd.get_dummies(df_combined[['User Age', 'Preferred Age Group', 'Seat Type']], drop_first=True)\n",
    "\n",
    "# Create new features if needed\n",
    "age_group_mapping = {'18-25': 1, '25-40': 2, '40-60': 3, '60+': 4}\n",
    "df_combined['Age Group Numeric'] = df_combined['Preferred Age Group'].map(age_group_mapping)\n",
    "\n",
    "# Scale numerical features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df_combined['Age Scaled'] = scaler.fit_transform(df_combined[['User Age']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33eeb434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Prepare features and target variable\n",
    "X = df_encoded\n",
    "y = df_combined['Seat Booked']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91b2db7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     User Age  Row  Column  Seat Type_Middle  Seat Type_Window  \\\n",
      "0           0    1       1             False              True   \n",
      "188         0   13       3              True             False   \n",
      "194         0   13       5              True             False   \n",
      "193         0   13       5             False             False   \n",
      "192         0   13       5             False              True   \n",
      "\n",
      "     Booking Probability  \n",
      "0                    1.0  \n",
      "188                  1.0  \n",
      "194                  1.0  \n",
      "193                  1.0  \n",
      "192                  1.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load booked seat data\n",
    "df_booked = pd.read_csv('train_booking_data.csv')\n",
    "\n",
    "# Define features and target\n",
    "X = df_booked[['User Age', 'Row', 'Column', 'Seat Type']]  # Features\n",
    "y = df_booked['Seat Booked']  # Target\n",
    "\n",
    "# Convert categorical features\n",
    "X = pd.get_dummies(X, columns=['Seat Type'], drop_first=True)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Generate synthetic data for all possible seat configurations\n",
    "rows = list(range(1, 20))\n",
    "columns = list(range(1, 6))\n",
    "seat_types = ['Window', 'Aisle', 'Middle']\n",
    "synthetic_data = []\n",
    "\n",
    "for row in rows:\n",
    "    for column in columns:\n",
    "        for seat_type in seat_types:\n",
    "            synthetic_data.append({\n",
    "                'User Age': 0,  # Placeholder\n",
    "                'Row': row,\n",
    "                'Column': column,\n",
    "                'Seat Type': seat_type\n",
    "            })\n",
    "\n",
    "df_synthetic = pd.DataFrame(synthetic_data)\n",
    "\n",
    "# Convert categorical features\n",
    "df_synthetic = pd.get_dummies(df_synthetic, columns=['Seat Type'], drop_first=True)\n",
    "\n",
    "# Predict probabilities\n",
    "df_synthetic_scaled = scaler.transform(df_synthetic)\n",
    "probabilities = model.predict_proba(df_synthetic_scaled)\n",
    "\n",
    "# Handle case where there is only one column\n",
    "if probabilities.shape[1] == 1:\n",
    "    df_synthetic['Booking Probability'] = probabilities\n",
    "else:\n",
    "    df_synthetic['Booking Probability'] = probabilities[:, 1]\n",
    "\n",
    "# Recommend seats based on probability\n",
    "recommended_seats = df_synthetic.sort_values(by='Booking Probability', ascending=False)\n",
    "print(recommended_seats.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "622dfeca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     User Age  Row  Column  Seat Type_Middle  Seat Type_Window  \\\n",
      "0          29    1       1             False              True   \n",
      "188        29   13       3              True             False   \n",
      "194        29   13       5              True             False   \n",
      "193        29   13       5             False             False   \n",
      "192        29   13       5             False              True   \n",
      "..        ...  ...     ...               ...               ...   \n",
      "101        29    7       4              True             False   \n",
      "102        29    7       5             False              True   \n",
      "103        29    7       5             False             False   \n",
      "104        29    7       5              True             False   \n",
      "284        29   19       5              True             False   \n",
      "\n",
      "     Booking Probability  \n",
      "0                    1.0  \n",
      "188                  1.0  \n",
      "194                  1.0  \n",
      "193                  1.0  \n",
      "192                  1.0  \n",
      "..                   ...  \n",
      "101                  1.0  \n",
      "102                  1.0  \n",
      "103                  1.0  \n",
      "104                  1.0  \n",
      "284                  1.0  \n",
      "\n",
      "[285 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Example of the trained model and scaler\n",
    "# model = RandomForestClassifier()\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# Function to recommend seats based on user's age and preferred age group\n",
    "def recommend_seats(user_age, preferred_age_group):\n",
    "    # Generate synthetic data for seat recommendations\n",
    "    rows = list(range(1, 20))\n",
    "    columns = list(range(1, 6))\n",
    "    seat_types = ['Window', 'Aisle', 'Middle']\n",
    "    synthetic_data = []\n",
    "\n",
    "    for row in rows:\n",
    "        for column in columns:\n",
    "            for seat_type in seat_types:\n",
    "                synthetic_data.append({\n",
    "                    'User Age': user_age,\n",
    "                    'Row': row,\n",
    "                    'Column': column,\n",
    "                    'Seat Type': seat_type\n",
    "                })\n",
    "\n",
    "    df_synthetic = pd.DataFrame(synthetic_data)\n",
    "\n",
    "    # Convert categorical features\n",
    "    df_synthetic = pd.get_dummies(df_synthetic, columns=['Seat Type'], drop_first=True)\n",
    "\n",
    "    # Scale features\n",
    "    df_synthetic_scaled = scaler.transform(df_synthetic)\n",
    "\n",
    "    # Predict probabilities\n",
    "    probabilities = model.predict_proba(df_synthetic_scaled)\n",
    "\n",
    "    # Handle case where there is only one column\n",
    "    if probabilities.shape[1] == 1:\n",
    "        df_synthetic['Booking Probability'] = probabilities\n",
    "    else:\n",
    "        df_synthetic['Booking Probability'] = probabilities[:, 1]\n",
    "\n",
    "    # Filter recommendations based on preferred age group\n",
    "    age_group_mapping = {\n",
    "        '18-25': (18, 25),\n",
    "        '25-40': (25, 40),\n",
    "        '40-60': (40, 60),\n",
    "        '60+': (60, 150)  # assuming age > 60\n",
    "    }\n",
    "\n",
    "    min_age, max_age = age_group_mapping.get(preferred_age_group, (0, 150))\n",
    "    filtered_recommendations = df_synthetic[\n",
    "        (df_synthetic['User Age'] >= min_age) & (df_synthetic['User Age'] <= max_age)\n",
    "    ]\n",
    "\n",
    "    # Sort by booking probability\n",
    "    recommended_seats = filtered_recommendations.sort_values(by='Booking Probability', ascending=False)\n",
    "\n",
    "    return recommended_seats\n",
    "\n",
    "# Example usage\n",
    "user_age = 29\n",
    "preferred_age_group = '25-40'\n",
    "recommended_seats = recommend_seats(user_age, preferred_age_group)\n",
    "print(recommended_seats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ced9a3ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Seat Type'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 64\u001b[0m\n\u001b[0;32m     62\u001b[0m user_age \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m29\u001b[39m\n\u001b[0;32m     63\u001b[0m preferred_age_group \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m25-40\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 64\u001b[0m preferred_seats \u001b[38;5;241m=\u001b[39m recommend_preferred_seats(user_age, preferred_age_group)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(preferred_seats\u001b[38;5;241m.\u001b[39mhead())\n",
      "Cell \u001b[1;32mIn[25], line 59\u001b[0m, in \u001b[0;36mrecommend_preferred_seats\u001b[1;34m(user_age, preferred_age_group)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Sort by booking probability\u001b[39;00m\n\u001b[0;32m     57\u001b[0m recommended_seats \u001b[38;5;241m=\u001b[39m filtered_recommendations\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBooking Probability\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m recommended_seats[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRow\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColumn\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSeat Type\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBooking Probability\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3766\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3767\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3769\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5877\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5874\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5875\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5877\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   5879\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   5880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5881\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5941\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5940\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 5941\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Seat Type'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Example of the trained model and scaler\n",
    "# model = RandomForestClassifier()\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "def recommend_preferred_seats(user_age, preferred_age_group):\n",
    "    # Generate synthetic data for seat recommendations\n",
    "    rows = list(range(1, 20))\n",
    "    columns = list(range(1, 6))\n",
    "    seat_types = ['Window', 'Aisle', 'Middle']\n",
    "    synthetic_data = []\n",
    "\n",
    "    for row in rows:\n",
    "        for column in columns:\n",
    "            for seat_type in seat_types:\n",
    "                synthetic_data.append({\n",
    "                    'User Age': user_age,\n",
    "                    'Row': row,\n",
    "                    'Column': column,\n",
    "                    'Seat Type': seat_type\n",
    "                })\n",
    "\n",
    "    df_synthetic = pd.DataFrame(synthetic_data)\n",
    "\n",
    "    # Convert categorical features\n",
    "    df_synthetic = pd.get_dummies(df_synthetic, columns=['Seat Type'], drop_first=True)\n",
    "\n",
    "    # Scale features\n",
    "    df_synthetic_scaled = scaler.transform(df_synthetic)\n",
    "\n",
    "    # Predict probabilities\n",
    "    probabilities = model.predict_proba(df_synthetic_scaled)\n",
    "\n",
    "    # Handle case where there is only one column\n",
    "    if probabilities.shape[1] == 1:\n",
    "        df_synthetic['Booking Probability'] = probabilities\n",
    "    else:\n",
    "        df_synthetic['Booking Probability'] = probabilities[:, 1]\n",
    "\n",
    "    # Filter recommendations based on preferred age group\n",
    "    age_group_mapping = {\n",
    "        '18-25': (18, 25),\n",
    "        '25-40': (25, 40),\n",
    "        '40-60': (40, 60),\n",
    "        '60+': (60, 150)  # assuming age > 60\n",
    "    }\n",
    "\n",
    "    min_age, max_age = age_group_mapping.get(preferred_age_group, (0, 150))\n",
    "    filtered_recommendations = df_synthetic[\n",
    "        (df_synthetic['User Age'] >= min_age) & (df_synthetic['User Age'] <= max_age)\n",
    "    ]\n",
    "\n",
    "    # Sort by booking probability\n",
    "    recommended_seats = filtered_recommendations.sort_values(by='Booking Probability', ascending=False)\n",
    "\n",
    "    return recommended_seats[['Row', 'Column', 'Seat Type', 'Booking Probability']]\n",
    "\n",
    "# Example usage\n",
    "user_age = 29\n",
    "preferred_age_group = '25-40'\n",
    "preferred_seats = recommend_preferred_seats(user_age, preferred_age_group)\n",
    "print(preferred_seats.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e059846a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
